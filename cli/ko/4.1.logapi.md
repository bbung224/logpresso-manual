# 4장. 실시간 로그 수집 설정

## 4.1. 로그 수집 설정

로그프레소에 내장된 여러가지 유형의 로그 수집기를 이용하여 데이터 원본을 구성할 수 있는데, 이를 로거(Logger)라고 부릅니다. 로그프레소는 로그 수집과 로그 저장 단계가 분리되어 있습니다. 따라서 로그에 대한 실시간 수집 및 분석만 수행하고 저장을 하지 않거나, 수집된 모든 로그를 특정한 테이블에 저장하도록 구성할 수 있습니다.

로거는 크게 액티브 로거와 패시브 로거로 구분됩니다. 액티브 로거는 설정된 주기에 따라 일정한 간격으로 동일한 동작을 반복 수행하는 로거를 의미합니다. 가령, 파일에서 로그를 수집하는 경우, 설정된 주기마다 파일의 증가분을 확인하여 로그를 읽어들입니다. 혹은 데이터베이스에서 일정 주기마다 테이블의 데이터를 읽어오는 예를 생각할 수 있습니다. 패시브 로거는 별도의 주기 없이 수동적으로 입력을 받아들이는 로거입니다. 가령 UDP 패킷을 수신해서 로깅하는 경우에는 별도의 실행 주기가 필요하지 않습니다.

이 절에서는 일반적인 로그 수집 설정에 대해서 다룹니다. 각 로그 수집 방법에 대해서는 별도의 절에서 사용 예와 함께 상세하게 설명합니다.

### 4.1.1. 로거 팩토리 목록 조회

로거 팩토리는 특정한 유형의 로거를 만들거나 삭제할 수 있도록 지원하는 구성요소입니다. 초기 설치 방식에 따라 다르지만, 보통은 아래와 같은 로거 팩토리가 기본으로 내장됩니다. `logapi.loggerFactories` 명령을 사용하여 전체 로거 팩토리 목록을 조회할 수 있습니다.

~~~
    araqne> logapi.loggerFactories
     Logger Factories
     +————–+——————————+
     | name | display name |
     +————–+——————————+
     | dirwatch | Directory watcher |
     | netflow | netFlow |
     | pcap | pcap |
     | selector | selector |
     | syslog | syslog logger |
     | syslog-relay | syslogger for relayed syslog |
     | textfile | Text file logger |
     +————–+——————————+
~~~

### 4.1.2. 로거 목록 조회

로거는 특정한 설정으로 생성된 데이터 원본에 해당됩니다. 가령, 특정한 원격지 IP에서 전송되는 시스로그를 수신하도록 설정된 syslog 로거를 구성할 수 있습니다. `logapi.loggers` 명령을 이용하여 전체 로거 목록을 조회할 수 있습니다.

~~~
    araqne> logapi.loggers
     Loggers
     +——————+———+———+————+———–+———-+
     | name | factory | status | intvl.(ms) | log count | last log |
     +——————+———+———+————+———–+———-+
     | local\flowtest | netflow | running | 0 | 0 | null |
     | local\syslog-all | syslog | running | 0 | 0 | null |
     +——————+———+———+————+———–+———-+
~~~

만약 특정한 문자열을 포함하는 로거만 검색하려고 한다면, 아래와 같이 명령합니다:

예시) flow를 포함하는 로거 목록 조회

~~~
	araqne> logapi.loggers flow
~~~

### 4.1.3. 로거 생성

로거 생성은 수집 방식과 관계없이 모두 동일한 명령어를 통해서 이루어집니다. `logapi.createLogger` 명령어의 사용법은 아래와 같습니다:

~~~
    araqne> logapi.createLogger
     Description

    create new logger

    Arguments

     1. logger factory name: logger factory name. try logapi.loggerFactories command. (required)
     2. logger namespace: new logger namespace (required)
     3. logger name: new logger name (required)
     4. description: the description of new logger (optional)
~~~

각 인자는 아래와 같습니다.

* 1.[필수] 로거 팩토리 이름: 이전에 `logapi.loggerFactories`를 사용하여 조회되는 로거 팩토리의 이름을 의미합니다.
* 2.[필수] 로거 이름공간: 이름이 겹치지 않도록 이름공간을 사용합니다. 로컬에서 만드는 로거는 관례적으로 “local” 문자열을 입력합니다. 원격지의 에이전트를 통해 연동되는 로거의 경우 해당 호스트의 식별자가 이름공간으로 사용됩니다.
* 3.[필수] 로거 이름: 로거 이름공간 안에서 겹치지 않는 이름을 임의로 부여할 수 있습니다.
* 4.[선택] 로거 설명: 로거에 대한 임의의 설명을 입력할 수 있습니다.

위의 인자를 모두 입력하여 명령을 실행하게 되면, 아래와 같이 로거 팩토리에 따라 추가적인 로거 설정 인자를 입력받습니다.

예시) syslog 로거 팩토리를 사용하여 nxg 로거 생성

~~~
    araqne> logapi.createLogger syslog local nxg
     remote ip (required)? 192.168.0.10
     syslog facility (optional)?
     transformer (optional, enter to skip)?
     logger created: name=local\nxg, factory=local\syslog, status=stopped (passive),
       log count=0, last start=null, last run=null, last log=null
~~~

위의 예에서 remote ip나 syslog facility는 syslog 로거 팩토리에 대해서만 입력받는 항목입니다. 로거 팩토리에 따라 다른 설정 입력을 요구받게 됩니다.

transformer는 수집되는 원본 로그에 대해 추가적인 변형이 필요할 때 사용합니다. 가령, 원본 로그에 대해 특정한 태깅을 하려는 경우에는 keyvalue 트랜스포머를 사용해서 트랜스포머 인스턴스를 생성하고 태깅을 수행할 수 있습니다. 트랜스포머에 대해서는 별도의 절에서 설명합니다.

### 4.1.4. 로거 시작

액티브 로거, 패시브 로거에 관계 없이 로거를 명시적으로 시작시켜야만 로그 수집 동작이 활성화됩니다. 다만, 패시브 로거의 경우 별도의 수집 주기 설정이 불필요하다는 차이가 있습니다.

로거를 시작시키려면 `logapi.startLogger` 명령을 사용합니다:

~~~
    araqne> logapi.startLogger
     Description

    start the logger

    Arguments

     1. logger fullname: the logger fullname to start (required)
     2. interval: sleep time of active logger thread in milliseconds. 60000ms by default.
         passive logger will ignore interval (optional)
~~~

* 1.[필수] 로거의 전체 이름: 이름공간\\이름 형식으로 로거의 전체 이름을 입력합니다.
* 2.[선택] 수집 동작 주기: 액티브 로거의 경우 몇 밀리초마다 동작할지 지정합니다. 기본값은 60초입니다.

### 4.1.5. 로거 정지

로거를 정지하려면 `logapi.stopLogger` 명령을 사용합니다:

~~~
    araqne> logapi.stopLogger
     Description

    stop the logger

    Arguments

     1. logger name: the logger name to stop (required)
     2. max wait time: max wait time in milliseconds (optional)
~~~

* 1.[필수] 로거의 전체 이름: 이름공간\\이름 형식으로 로거의 전체 이름을 입력합니다.
* 2.[선택] 로거가 정지할 때까지 최대 몇 밀리초를 기다릴지 지정합니다. 기본값은 5초입니다.

### 4.1.6. 로거 삭제

`logapi.removeLogger` 명령을 사용하여 로거를 삭제할 수 있습니다. 만약 로거가 동작하고 있으면 정지시킨 후에 삭제합니다:

~~~
    araqne> logapi.removeLogger
     Description

    remove logger

    Arguments

    1. logger fullname: the logger fullname (required)
~~~

* 1.[필수] 로거의 전체 이름: 이름공간\\이름 형식으로 로거의 전체 이름을 입력합니다.

### 4.1.7. 마지막 로그 조회

(araqne-log-api 2.6.0부터 지원)

`logapi.lastLogs` 명령을 사용하여 로거별로 시스템 부팅 후 수집된 마지막 로그를 조회할 수 있습니다. 첫번째 인자를 주면 로거 이름에 대하여 필터링을 수행합니다.

~~~
    araqne@bombom demo> logapi.lastLogs
    —-
    Logger [local\wtmp] Last Timestamp [2013-09-02 22:38:25+0900]
     {host=182.209.194.63, session=0, pid=8917, type=UserProcess, user=xeraph}
    —-
    Logger [local\iis] Last Timestamp [2013-09-19 13:44:02+0900]
     {line=2007-10-22 01:47:53 W3SVC1 123.223.21.233 GET /solution/1.982/asp/strawlv01982_msg.asp
       t=1&m=0013D4E55911 80 – 111.217.245.234 UtilMind+HTTPGet 200 0 0}
~~~

## 4.2. 디렉터리 로그 파일 수집 설정

디렉토리 와치 (dirwatch) 로거는 롤링되지 않는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 가령 일자별 혹은 시간대별로 순차 생성되는 로그 파일을 수집할 때 사용합니다. 디렉토리 와치 로거는 아래와 같은 설정을 입력받습니다:
* [필수] 디렉터리 경로: 로그 파일이 위치하는 파일시스템 경로를 의미합니다.
* [필수] 파일이름 정규표현식 패턴: 디렉터리 경로에 존재하는 파일 중 이름이 정규표현식 패턴에 일치하는 경우에만 수집합니다. 정규표현식 그룹을 쓰는 경우 파일 이름에서 날짜 문자열을 추출합니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다. 파일이름 정규표현식의 그룹으로 추출된 날짜문자열은 가장 앞 부분에 위치합니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 날짜 로케일: 날짜 문자열의 로케일. 가령 날짜 파싱 포맷의 지시자 중 MMM의 해석은 로케일에 따라 “Jan” 혹은 “1월”로 해석됩니다.  기본값은 en입니다.
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 문자집합: 텍스트 파일 해석에 사용할 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.

여러 개의 파일이 수집 대상인 경우, 파일의 절대 경로를 사전순으로 정렬하여 순서대로 읽어들입니다. 이하에서는 여러가지 사용 예를 살펴보도록 하겠습니다.

예시 1) /var/log/examples 디렉터리에 example.log.yyyy-MM-dd-HH 로그 파일이 순차 생성되는 경우

0;20130615 141618;192.168.0.10;E002;20130615 141618;192.168.0.11;
* 디렉터리 경로: /var/log/examples
* 파일이름 정규표현식 패턴: example\.log.*
* 날짜 추출 정규표현식 패턴: ^\d+;(\d{8} \d{6});
* 날짜 파싱 포맷: yyyyMMdd HHmmss

예시 2) /logdata/c6509 디렉터리에 c6509.log.yyyyMMdd 로그 파일이 쌓이는 경우

May 01 23:59:59: %LINK-SP-3-UPDOWN: Interface GigabitEthernet8/15, changed state to down
* 디렉터리 경로: /logdata/c6509
* 파일이름 정규표현식 패턴: c6509\.log\.(\d{8})
* 날짜 추출 정규표현식 패턴: ^[^ ]* \d{2} (\d{2}):(\d{2}):(\d{2})
* 날짜 파싱 포맷: yyyyMMddHHmmss
 (파일이름 정규표현식으로 추출된 yyyyMMdd 그룹 1개와 날짜 추출 정규표현식에서 추출된 HH, mm, ss 그룹 3개가 하나로 병합되어 파싱됩니다.)

예시 3) /araqne/log 디렉터리에 araqne.log.yyyy-MM-dd 파일이 순차 생성되는 경우

~~~
    [2013-06-14 13:55:02,186]  INFO (LogIndexerEngine) - logpresso index: counter reset thread started
    [2013-06-14 13:55:40,647]  WARN (ScriptRunner) - script runner: 
    java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.araqne.console.ScriptRunner.invokeScript(ScriptRunner.java:209)
        at org.araqne.console.ScriptRunner.run(ScriptRunner.java:190)
        at java.lang.Thread.run(Unknown Source)
          Caused by: java.lang.InterruptedException
        at org.araqne.console.ReadLineHandler.read(ReadLineHandler.java:156)
        at org.araqne.console.ReadLineHandler.getLine(ReadLineHandler.java:46)
        at org.araqne.console.ConsoleInputStream.readLine(ConsoleInputStream.java:56)
        at org.araqne.script.ScriptContextImpl.readLine(ScriptContextImpl.java:194)
        at org.araqne.log.api.impl.LogApiScript.setOption(LogApiScript.java:629)
        at org.araqne.log.api.impl.LogApiScript.createParser(LogApiScript.java:99)
        ... 7 more
~~~

* 디렉터리 경로: /araqne/log
* 파일이름 정규표현식 패턴: araqne\.log.*
* 날짜 추출 정규표현식 패턴: \[(.*),
* 날짜 파싱 포맷: yyyy-MM-dd HH:mm:ss
* 로그 구분자 정규식: \[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\]


## 4.3.  선택자 로그 수집 설정

선택자 (selector) 로거는 다른 로거에서 수집하는 데이터 중 일부만 선택적으로 가져오려고 할 때 사용합니다. 선택자 로거는 아래와 같은 설정을 입력받습니다:
* [필수] 원본 로거 이름: 네임스페이스를 포함한 원본 로거 이름을 입력합니다.
* [필수] 텍스트 패턴: 원본 데이터의 line 필드 값과 비교할 접두어 문자열을 입력합니다. 가령, 0; 으로 입력하면 line 필드 값이 0; 으로 시작하는 로그만 수집하게 됩니다.

예시) local\\apache 이름의 아파치 로그 수집기로부터 10.x 대역 IP 로그만 수집하는 local\\filtered 로거 생성

~~~
    araqne@bombom demo> logapi.createLogger selector local filtered
     Source logger name (required)? local\apache
     Text pattern (required)? 10.
     transformer (optional, enter to skip)?
     logger created: name=local\filtered, factory=local\selector, status=stopped (passive),
       log count=0, last start=null, last run=null, last log=null
 ~~~


## 4.4. 정규표현식 선택자 로그 수집 설정

araqne-log-api 2.8.4 버전부터 지원

정규표현식 선택자 (regex-selector) 로거는 다른 로거에서 수집하는 데이터 중 정규표현식과 일치하는 데이터만 선택적으로 가져오려고 할 때 사용합니다. 정규표현식 선택자 로거는 아래와 같은 설정을 입력받습니다:
* [필수] 원본 로거 이름: 네임스페이스를 포함한 원본 로거 이름을 입력합니다.
* [필수] 정규표현식: 원본 데이터의 line 필드 값과 비교할 정규표현식을 입력합니다.
* [선택] 매칭 결과 반전: 정규표현식이 매칭되지 않는 데이터를 수집하려면  true를 설정합니다. 미설정 시 패턴 매칭된 데이터를 수집합니다. (araqne-log-api 2.9.4 버전부터 지원)

예시) local\netscreen 이름의 넷스크린 로그 수집기로부터 NETBIOS 서비스가 차단된 방화벽 로그만 수집하는 local\filtered 로거 생성

매칭되는 로그 예시

~~~
Aug 09 09:00:20 [121.133.51.213] SSG140: NetScreen device_id=SSG140  [Root]system-notification-00257(traffic): start_time=”2012-08-09 09:00:20″ duration=0 policy_id=16 service=NETBIOS (NS) proto=17 src zone=V1-Untrust dst zone=V1-Trust action=Deny sent=0 rcvd=0 src=21.133.10.111 dst=121.113.40.255 src_port=137 dst_port=137 session_id=0
~~~

설정 예시

~~~
araqne@bombom demo> logapi.createLogger regex-selector local filtered
 Source logger name (required)? local\netscreen
 Regex pattern (required)? service=NETBIOS(.*?)action=Deny
 transformer (optional, enter to skip)?
 logger created: name=local\filtered, factory=local\regex-selector, status=stopped (passive), log count=0, last start=null, last run=null, last log=null
 ~~~

## 4.5. 로테이션 로그 파일 수집 설정


로테이션 (rotation) 로거는 주기적으로 로테이션 되는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 흔히 리눅스 서버에서는 logrotate 프로그램을 사용하여 일정 주기로 기존 파일의 이름을 변경하여 백업 보관하고 로그 파일을 새로 생성합니다. 로테이션 로거는 이런 시나리오에서 사용되며, 다음과 같은 설정을 입력받습니다:
* [필수] 파일 경로: 주기적으로 로테이션 되는 텍스트 로그 파일의 절대 경로를 입력합니다.
* [선택] 문자집합: 텍스트 파일 해석에 사용할 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 날짜 로케일: 날짜 문자열의 로케일. 가령 날짜 파싱 포맷의 지시자 중 MMM의 해석은 로케일에 따라 “Jan” 혹은 “1월”로 해석됩니다.  기본값은 en입니다.
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.

예시 1) /var/log/httpd/access_log 파일이 로테이션 되는 경우
127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] "GET /apache_pb.gif HTTP/1.0" 200 2326
* 파일 경로: /var/log/httpd/access_log
* 날짜 추출 정규표현식 패턴: \[(.*?)\]
* 날짜 파싱 포맷: dd/MMM/yyyy:HH:mm:ss Z
* 날짜 로케일: en

예시 2) /araqne/log/araqne.log 파일이 로테이션 되는 경우

~~~
    [2013-06-14 13:55:02,186]  INFO (LogIndexerEngine) - logpresso index: counter reset thread started
    [2013-06-14 13:55:40,647]  WARN (ScriptRunner) - script runner: 
    java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
        at java.lang.reflect.Method.invoke(Unknown Source)
        at org.araqne.console.ScriptRunner.invokeScript(ScriptRunner.java:209)
        at org.araqne.console.ScriptRunner.run(ScriptRunner.java:190)
        at java.lang.Thread.run(Unknown Source)
    Caused by: java.lang.InterruptedException
        at org.araqne.console.ReadLineHandler.read(ReadLineHandler.java:156)
        at org.araqne.console.ReadLineHandler.getLine(ReadLineHandler.java:46)
        at org.araqne.console.ConsoleInputStream.readLine(ConsoleInputStream.java:56)
        at org.araqne.script.ScriptContextImpl.readLine(ScriptContextImpl.java:194)
        at org.araqne.log.api.impl.LogApiScript.setOption(LogApiScript.java:629)
        at org.araqne.log.api.impl.LogApiScript.createParser(LogApiScript.java:99)
        ... 7 more
~~~

* 파일 경로: /araqne/log/araqne.log
* 날짜 추출 정규표현식 패턴: \[(.*),
* 날짜 파싱 포맷: yyyy-MM-dd HH:mm:ss
* 로그 시작 정규식: \[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\]


## 4.6. 외부 프로그램 표준 출력 수집 설정

외부 프로그램 표준 출력 수집 (exec) 로거는 지정된 명령어의 실행 결과를 수집합니다. 로그프레소 서버에 설치된 프로그램 혹은 스크립트 등을 실행하여 표준 출력으로 나오는 문자열 전체를 하나의 로그로 수집합니다. 외부 프로그램 표준 출력 수집 로거는 아래와 같은 설정을 입력받습니다:
* [필수] 명령어: 쉘에서 실행할 명령어를 입력합니다.

예시) 리눅스 호스트의 load average 로그 수집
* 명령어: cat /proc/loadavg

실시간 로그 트레이스 결과

~~~
    araqne> logapi.trace local\loadavg
    tracing logger: name=local\loadavg, factory=local\exec, status=running (interval=1000ms),
      log count=0, last start=2013-08-18 20:07:39, last run=null, last log=null
    local\loadavg: date=2013-08-18 20:07:56, logger=local\loadavg, data={line=0.38 0.17 0.11 1/358 18042}
    local\loadavg: date=2013-08-18 20:08:14, logger=local\loadavg, data={line=0.27 0.16 0.11 1/357 18101}
    local\loadavg: date=2013-08-18 20:08:32, logger=local\loadavg, data={line=0.21 0
~~~


## 4.7. WTMP 로그 수집 설정

araqne-log-api 2.5.1 버전부터 지원

WTMP 로거는 터미널 로그인 및 로그아웃 시 발생하는 wtmp 레코드를 일정 주기마다 수집합니다. WTMP 로거는 다음과 같은 설정을 입력받습니다:
* [필수] 파일 경로: wtmp 파일의 절대 경로를 입력합니다. 일반적으로 /var/log/wtmp 위치에 존재합니다.

로그 수집 시 다음과 같은 필드들이 기록됩니다:
* type: Unknown, RunLevel, BootTime, NewTime, OldTime, InitProcess, LoginProcess, UserProcess, DeadProcess, Accounting 문자열 중 하나. 로그인 시 UserProcess, 로그아웃 시 DeadProcess 타입으로 기록됩니다.
* host: 원격 접속지 주소
* pid: 프로세스 식별자
* session: 세션 식별자
* user: 계정 이름

아래는 수집된 wtmp 로그 예시입니다.

~~~
    type=BootTime, date=2013-05-13 16:07:17, pid=0, user=reboot, host=2.6.18-274.7.1.el5xen
    type=RunLevel, date=2013-05-13 16:07:17, pid=20019, user=runlevel, host=2.6.18-274.7.1.el5xen
    type=InitProcess, date=2013-05-13 16:07:17, pid=717, user=, host=2.6.18-274.7.1.el5xen
    type=DeadProcess, date=2013-05-13 16:07:20, pid=717, user=, host=2.6.18-274.7.1.el5xen
    type=InitProcess, date=2013-05-13 16:07:20, pid=1368, user=, host=2.6.18-274.7.1.el5xen
    type=LoginProcess, date=2013-05-13 16:07:20, pid=1368, user=LOGIN, host=
    type=UserProcess, date=2013-05-13 16:44:25, pid=2927, user=8con, host=120.130.206.219
    type=UserProcess, date=2013-05-13 17:19:07, pid=4265, user=8con, host=120.161.231
~~~


## 4.8. 로그프레소 시스로그 수집 설정


시스로그 서버와 로거를 이용하여 실시간으로 시스로그를 수집하고 테이블에 저장할 수 있습니다.

### 4.8.1. 시스로그 서버 관리

#### 4.8.1.1 시스로그 포트 열기

지정된 이름 및 설정으로 시스로그 포트를 개방합니다.

~~~
    araqne> syslog.open
     Description

    open persistent syslog server

    Arguments

    1. server name: unique server name (required)
     2. port: syslog port number (optional)
     3. address: syslog bind address. 0.0.0.0 by default (optional)
     4. charset: character set name. utf-8 by default (optional)
     5. queue size: buffering queue size. 20000 by default (optional)
     6. buffer size: os receive buffer size (optional)
~~~

포트를 지정하지 않으면 기본 시스로그 포트인 514로 설정됩니다. 문자집합을 지정하지 않으면 utf-8이 기본값으로 사용됩니다. 큐 크기는 시스로그를 수신하는 패킷 풀의 크기를 의미합니다. 버퍼 크기는 운영체제의 UDP 수신 버퍼 크기 설정을 의미합니다.

UDP 손실율을 최소화하려면 큐 크기와 수신 버퍼 크기를 주어진 실행 환경에서 가능한 크게 설정합니다. 그러나 JVM 최대 메모리 설정에 비하여 무리하게 패킷 큐 크기를 증가시키는 경우 잦은 GC를 유발하여 오히려 성능이 저하될 수 있습니다.

#### 4.8.1.2. 시스로그 포트 닫기

지정된 이름의 시스로그 포트를 닫습니다.

~~~
    araqne> syslog.close
     Description

    close syslog server

    Arguments

    1. server name: the name of syslog server instance (required)
~~~

예시) “default”라는 이름의 포트 닫기

~~~
    araqne> syslog.close default
     closed
~~~

#### 4.8.1.3. 시스로그 서버 목록 조회

현재 열려있는 포트 설정과 함께 수신 현황과 대기 현황을 표시합니다.

~~~
    araqne> syslog.servers
     Syslog Servers
    —————-
    [default] 0.0.0.0:514, charset=utf-8, capacity=20000, rx_buf_size=0, since=2013-06-05 02:25:53, received=0, pending=0
~~~

#### 4.8.1.4. 실시간 시스로그 트레이스

시스로그가 정상적으로 수신되는지 확인하려고 할 때 실시간 트레이스 명령을 사용할 수 있습니다. 실시간 트레이스를 중지하려면 Ctrl-C를 입력합니다.

~~~
    araqne> syslog.trace
     Description

    trace a syslog receiver.

    Arguments

    1. server name: the name of syslog server instance (required)
~~~

예시)

~~~
    araqne> syslog.trace default
     press ctrl-c to stop
    ————————
    [2013-06-05 02:28:13.536+0900] (/127.0.0.1:51245) => [fc:16, sv:5] FW-A: NetScreen device_id=FW-A [Root]system-notification-00257(traffic): start_time=”2013-05-14 14:45:44″ duration=0 policy_id=1175 service=udp/port:16500 proto=17 src zone=Trust dst zone=Untrust action=Deny sent=0 rcvd=112 src=130.1.246.11 dst=130.1.168.49 src_port=16500 dst_port=16500 session_id=0
~~~

### 4.8.2. 시스로그 로거 설정

#### 4.8.2.1 시스로그 로거 생성 및 시작

로거 생성은 로거의 유형에 관계없이 공통 인터페이스를 따릅니다. 아래의 명령을 사용하여 시스로그 로거를 생성할 수 있습니다:

예시) 1.2.3.4에서 PRI 없이 전송된 시스로그를 수신하는 설정

~~~
    araqne> logapi.createLogger syslog local name
     remote ip (required)? 1.2.3.4
     syslog facility (required)? -1
     transformer (optional, enter to skip)?
     logger created: name=local\name, factory=local\syslog, status=stopped (passive), 
       log count=0, last start=null, last run=null, last log=null
~~~

name은 사용자가 원하는 로거 이름을 입력합니다. remote ip 설정 항목은 시스로그를 전송하는 장비의 IP 주소를 기입합니다. NAT 환경인 경우 로그프레소 서버 측에서 보이는 원격지 주소, 즉, NAT 된 주소를 입력하면 됩니다. syslog facility 항목은 PRI (<123> 같은 시스로그 헤더 부분)가 없는 경우 -1, 그렇지 않으면 쉼표 (,)로 facility 값을 이어붙여서 입력하면 됩니다. 가령 facility에 구분없이 해당 장비에서 발생하는 모든 시스로그를 수신하려고 한다면, RFC 5424에 나온대로 -1부터 23까지 모두 입력하면 됩니다. (즉, -1,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23 으로 입력)

로거를 생성했으면 아래의 명령으로 시작시킵니다.

~~~
    araqne> logapi.startLogger local\name
     logger started
~~~

로거 상태 조회 명령으로 시스로그가 서버에서 수신된 후 로거까지 도달했는지 확인할 수 있습니다:

~~~
    araqne> logapi.logger local\name
     Logger [local\name]
    ——————–
    * Description: null
     * Logger Factory: local\syslog
     * Status: Running
     * Interval: 0ms
     * Last Log: N/A
     * Last Run: N/A
     * Log Count: 0

    Configuration
    —————
    * facility: -1
     * remote_ip: 1.2.3.4
~~~

#### 4.8.2.2. 시스로그 저장 설정

이전 단계에서 생성한 로거가 시스로그 데이터 소스로서 기능한다고 하더라도, 명시적으로 로그 저장 설정을 해야만 수신된 시스로그가 테이블에 저장됩니다.

~~~
    araqne> logpresso.createLogger
     Description

    create managed logger

    Arguments

     1. org domain: org domain (required)
     2. logger fullname: logger fullname (required)
     3. table name: destination table name, use logger fullname if not specified (optional)
     4. host: host name will be recorded to log data if specified (optional)
~~~

첫번째 매개변수는 localhost 도메인을, 두번째 매개변수는 로거의 전체 이름을 입력합니다. 세번째 매개변수는 저장할 테이블 이름을 입력합니다. 네번째 항목을 설정하면 해당 문자열을 로그에 _host 필드 이름으로 태깅합니다. 즉, 여러 장비의 로그를 한 테이블에 저장했을 때 태그로 각 호스트를 구분할 수 있도록 지원하는 것입니다.

예시)

~~~
    araqne> logpresso.createLogger localhost local\name syslogs
     created
~~~

이제 `syslog.servers`와 `logapi.logger` 명령으로 로그 수신 상태를 확인한 후, `logdb.console` 명령으로 DB 콘솔에 접속하여 올바르게 시스로그 원본이 저장되었는지 쿼리하여 확인합니다.


## 4.9. 로그프레소 SNMP GET 수집 설정

logpresso-snmpmon 0.5.0 버전부터 지원

SNMP GET (snmpget) 로거는 SNMP 에이전트를 대상으로 쿼리를 수행한 결과를 수집합니다. 아래와 같이 에이전트 접속 정보와 OID-필드이름 매핑 목록을 설정합니다:
* [필수] SNMP 프로토콜 버전: v1, v2c 중 하나를 입력합니다.
* [필수] 에이전트 IP 주소: SNMP 에이전트의 호스트 이름 혹은 IP 주소를 입력합니다.
* [선택] SNMP 포트: SNMP 쿼리를 수행할 때 사용할 UDP 포트 번호를 입력합니다. 미설정 시 기본값으로 161이 설정됩니다.
* [필수] SNMP 커뮤니티: SNMP 인증에 사용할 커뮤니티 문자열을 입력합니다. 읽기 전용으로는  관례적으로 public이 흔히 사용됩니다.
* [필수] OID 매핑 목록: 수집할 대상 Object ID와 필드 이름의 쌍을 쉼표로 구분하여 입력합니다. 로그 수집 시 OID가 지정한 필드 이름으로 변환되어 값과 함께 기록됩니다.
* [선택] 쿼리 타임아웃: 초 단위로 쿼리 응답 만료시간을 지정합니다. 미설정 시 5초로 지정됩니다.
* [선택] 재시도 횟수: 쿼리 실패 시 몇 번 재시도 할 것인지 지정합니다. 미설정 시 2회로 지정됩니다.

예시) NET-SNMP 에이전트를 대상으로 CPU 사용률 수집
* SNMP 프로토콜 버전: v2c
* 에이전트 IP 주소: hostname
* SNMP 포트: 161
* SNMP 커뮤니티: public
* OID 매핑 목록: .1.3.6.1.4.1.2021.11.10.0=system, .1.3.6.1.4.1.2021.11.9.0=user

로거를 시작시키면 지정된 시간 간격으로 아래와 같이 수집됩니다:

~~~
    tracing logger: name=local\snmp_cpu, factory=local\snmpget, status=running (interval=1000ms),
      log count=8, last start=2014-01-10 19:56:08, last run=2014-01-10 19:56:15, 
      last log=2014-01-10 19:56:15
     local\snmp_cpu: date=2014-01-10 19:56:16, logger=local\snmp_cpu, data={system=0, user=25}
     local\snmp_cpu: date=2014-01-10 19:56:17, logger=local\snmp_cpu, data={system=0, user=25}
~~~

## 4.10. 로그프레소 SNMP 트랩 수집 설정

SNMP 서버와 로거를 이용하여 실시간으로 SNMP 패킷을 수집하고 테이블에 저장할 수 있습니다.

### 4.10.1. SNMP 트랩 서버 관리

##### 4.10.1.1. SNMP 트랩 포트 열기

지정된 이름 및 설정으로 SNMP 트랩 포트를 개방합니다.

~~~
    araqne> snmp.openTrapPort
     Description

    open trap port

    Arguments

     1. name: trap binding name (required)
     2. port: trap port (162 by default) (optional)
     3. address: trap address (0.0.0.0 by default) (optional)
~~~

* [필수] 바인딩 설정 이름
* [선택] UDP 트랩 포트, 기본값 162
* [선택] IP 주소, 기본값은 0.0.0.0으로 모든 인터페이스에 바인딩

#### 4.10.1.2. SNMP 트랩 포트 닫기

~~~
    araqne> snmp.closeTrapPort
     Description

    close trap port

    Arguments

    1. name: trap binding name (required)
~~~

지정된 이름으로 열려있는 트랩 포트를 닫습니다.

#### 4.10.1.3. 트랩 서버 목록 조회

현재 열려있는 SNMP 트랩 서버 목록을 출력합니다.

~~~
    araqne> snmp.trapBindings
     Trap Bindings
    —————
    default => name=default, listen=0.0.0.0/0.0.0.0:162, thread=1
~~~

#### 4.10.1.4. 실시간 SNMP 트랩 수신 출력

SNMP 트랩 패킷이 수신될 때마다 원격지의 주소와 변수 바인딩 목록을 실시간으로 출력합니다. 출력을 중지하려면 Ctrl-C를 누릅니다.

~~~
araqne> snmp.trace
 press ctrl-c to stop
———————-
127.0.0.1:62454 {1.3.6.1.4.1.33957.1.2.4=test, 1.3.6.1.4.1.33957.1.2.5=1, 1.3.6.1.4.1.33957.1.2.6=testrulegroup, 1.3.6.1.4.1.33957.1.2.20=http, 1.3.6.1.4.1.33957.1.2.7=eth0, 1.3.6.1.4.1.33957.1.2.1=1101, 1.3.6.1.4.1.33957.1.2.2=20111205225000+0900, 1.3.6.1.4.1.33957.1.2.3=31, 1.3.6.1.4.1.33957.1.1.1=ML11170001, 1.3.6.1.4.1.33957.1.1.2=1, 1.3.6.1.4.1.33957.1.2.8=eth1, 1.3.6.1.4.1.33957.1.2.9=/172.20.2.25, 1.3.6.1.4.1.33957.1.2.19=http, 1.3.6.1.4.1.33957.1.2.13=60018, 1.3.6.1.4.1.33957.1.2.14=80, 1.3.6.1.4.1.33957.1.2.11=/74.125.71.106, 1.3.6.1.4.1.33957.1.2.22=http, 1.3.6.1.4.1.33957.1.2.23=soul, 1.3.6.1.4.1.33957.1.2.18=172.20.2.25_60018_74.125.71.106_80_1234.pcap, 1.3.6.1.4.1.33957.1.2.21.1=raph, 1.3.6.1.4.1.33957.1.2.15=001122334455, 1.3.6.1.4.1.33957.1.2.16=001122334455}
~~~

### 4.10.2. SNMP 트랩 로거 설정

#### 4.10.2.1. SNMP 트랩 로거 생성 및 시작

로거 생성은 로거의 유형과 관계없이 공통 인터페이스를 따릅니다. 아래의 명령을 사용하여 SNMP 트랩 로거를 생성할 수 있습니다:

예시) 1.2.3.4에서 전송된 SNMP 트랩 로그를 수신하는 설정

~~~
araqne> logapi.createLogger snmptrap local trapsample
 remote ip (required)? 1.2.3.4
 transformer (optional, enter to skip)?
 logger created: name=local\trapsample, factory=local\snmptrap, status=stopped (passive), log count=0, last start=null, last run=null, last log=null
~~~

remote ip 설정 항목은 SNMP 트랩을 전송하는 장비의 IP 주소를 기입합니다. NAT 환경인 경우 로그프레소 서버 측에서 보이는 원격지 주소, 즉 NAT된 주소를 입력하면 됩니다.

로거를 생성했으면 아래의 명령으로 시작시킵니다.

~~~
    araqne> logapi.startLogger local\trapsample
     logger started
~~~

#### 4.10.2.2. SNMP 트랩 로그 저장 설정

수집되는 SNMP 트랩 로그를 저장하려면, 명시적으로 로그 저장 설정을 해야합니다.

~~~
    araqne> logpresso.createLogger
     Description

    create log archive

    Arguments

     1. org domain: org domain (required)
     2. logger fullname: logger fullname (required)
     3. table name: destination table name, use logger fullname if not specified (optional)
     4. host: host name will be recorded to log data if specified (optional)
~~~

첫번째 매개변수는 localhost 도메인을, 두번째 매개변수는 로거의 전체 이름을 입력합니다. 세번째 매개변수는 저장할 테이블 이름을 입력합니다. 네번째 항목을 설정하면 해당 문자열을 로그에 _host 필드 이름으로 태깅합니다. 즉, 여러 장비의 로그를 한 테이블에 저장했을 때 태그로 각 호스트를 구분할 수 있도록 지원하는 것입니다.

예시) local\\trapsample 로거로 수집되는 모든 로그를 traps 테이블에 저장

~~~
    araqne> logpresso.createLogger localhost local\trapsample traps
~~~

이제 `logapi.logger` 명령으로 로그 수신 상태를 확인한 후, `logdb.console` 명령으로 DB 콘솔에 접속하여 올바르게 SNMP 트랩이 저장되었는지 쿼리하여 확인합니다.


## 4.11. SNMP 트랩 로거 설정넷플로우 로그 수집 설정

넷플로우 서버와 로거를 이용하여 실시간으로 넷플로우 로그를 수집하고 테이블에 저장할 수 있습니다. netflow v5와 v9 패킷을 지원합니다.

### 4.11.1. 넷플로우 서버 관리

#### 4.11.1.1. 넷플로우 포트 열기

~~~
    araqne> flowmon.open
     Description

    open netflow port

    Arguments

     1. name: binding name (required)
     2. port: udp port for netflow collector (required)
~~~

* [필수] 바인딩 이름. 임의의 이름을 부여합니다.
* [필수] 넷플로우를 수신할 UDP 포트 번호

예시) default 라는 이름으로 9090 포트 개방

~~~
    araqne> flowmon.open default 9090
     port opened
~~~

#### 4.11.1.2. 넷플로우 포트 목록 조회

현재 열려있는 넷플로우 포트 목록을 조회하려면 flowmon.bindings 명령을 실행합니다:

~~~
    araqne> flowmon.bindings
     Port Bindings
    —————
    name=default, port=9090
~~~

#### 4.11.1.3. 실시간 넷플로우 트레이스

넷플로우 패킷이 정상적으로 수신되고 있는지 확인하려고 할 때 실시간 트레이스 명령을 사용할 수 있습니다. 실시간 트레이스를 중지하려면 Ctrl-C를 입력합니다.

~~~
araqne> flowmon.trace default
 press ctrl-c to stop
————————
[127.0.0.1:60772] ver=5, count=30, sysuptime=223215, unixsecs=1369017127, unixnsecs=26, seq=696, engine_type=0, engine_id=71, sampling_mode=0, sampling_interval=0
 [127.0.0.1:60772] ver=9, count=3, sys_uptime=42212, unixsecs=1369122709, seq=0, source=106
 interrupted
~~~

#### 4.11.1.4. 넷플로우 포트 닫기

지정된 이름의 넷플로우 포트를 닫습니다.

예시) default 넷플로우 포트 닫기

~~~
    araqne> flowmon.close default
     port closed
~~~

### 4.11.2. 넷플로우 로거 설정

넷플로우 로거는 넷플로우 패킷을 수신한 후 개별 플로우 레코드에 대하여 로그를 발생시킵니다. 1개의 넷플로우 패킷이 수십 개의 플로우 레코드를 포함할 수 있습니다.

#### 4.11.2.1. 넷플로우 로거 생성 및 시작

로거 생성은 로거의 유형에 관계없이 공통 인터페이스를 따릅니다. 아래의 명령을 사용하여 넷플로우 로거를 생성할 수 있습니다:

예시) 모든 넷플로우 패킷 수신

~~~
araqne> logapi.createLogger netflow local netflow-logger
 Source ID List (optional)?
 Field Name Filter (optional)?
 transformer (optional, enter to skip)?
 logger created: name=local\netflow-logger, factory=local\netflow, status=stopped (passive), log count=0, last start=null, last run=null, last log=null
~~~

소스 ID 목록은 넷플로우 패킷을 전송하는 측에서 설정한 ID를 의미합니다. 입력하지 않으면 필터링 없이 모든 패킷을 수신합니다. 쉼표로 구분하여 여러 개의 ID를 입력할 수 있습니다. 또한 필드 이름 필터를 사용해서 전송된 플로우 레코드 중 특정한 필드만 저장하도록 설정할 수 있습니다. 마찬가지로 쉼표로 구분된 필드 이름들을 입력할 수 있습니다.

로거를 생성했으면 아래의 명령으로 시작시킵니다.

~~~
    araqne> logapi.startLogger local\netflow-logger
     logger started
~~~

로거 상태 조회 명령으로 넷플로우 패킷이 서버에서 수신된 후 로거까지 도달했는지 확인할 수 있습니다:

~~~
    araqne> logapi.logger local\netflow-logger
     Logger [local\netflow-logger]
    ——————————
    * Description: null
     * Logger Factory: local\netflow
     * Status: Running
     * Interval: 0ms
     * Last Log: 2013-06-15 17:54:47
     * Last Run: N/A
     * Log Count: 31

    Configuration
    —————
~~~

#### 4.11.2.2. 넷플로우 로그 저장 설정

이전 단계에서 생성한 로거가 넷플로우 데이터소스로서 기능한다고 하더라도, 명시적으로 로그 저장 설정을 해야만 수신된 넷플로우 로그가 테이블에 저장됩니다.

~~~
    araqne> logpresso.createLogger
     Description

    create managed logger

    Arguments

     1. org domain: org domain (required)
     2. logger fullname: logger fullname (required)
     3. table name: destination table name, use logger fullname if not specified (optional)
     4. host: host name will be recorded to log data if specified (optional)
~~~

첫번째 매개변수는 localhost 도메인을, 두번째 매개변수는 로거의 전체 이름을 입력합니다. 세번째 매개변수는 저장할 테이블 이름을 입력합니다. 네번째 항목을 설정하면 해당 문자열을 로그에 _host 필드 이름으로 태깅합니다. 즉, 여러 장비의 로그를 한 테이블에 저장했을 때 태그로 각 호스트를 구분할 수 있도록 지원하는 것입니다.

예시) local\\netflow-logger에서 발생한 모든 로그를 netflows 테이블에 저장

~~~
    araqne> logpresso.createLogger localhost local\netflow-logger netflows
     created
~~~

이제 `logapi.logger` 명령으로 수신 상태를 확인한 후, `logdb.consol`e 명령으로 DB 콘솔에 접속하여 올바르게 넷플로우 로그가 저장되었는지 쿼리하여 확인합니다.

~~~
araqne@logdb> query table netflows | stats count, sum(octet_count), sum(packet_count)
 {count=62, sum(octet_count)=298138, sum(packet_count)=408}
 total 1 rows, elapsed 0.1s
~~~


## 4.12. JDBC 수집 설정

logpresso-jdbc 0.1.0 버전부터 지원

JDBC 로거는 SQL 쿼리를 사용하여 데이터베이스의 테이블나 뷰에서 데이터를 수집하려고 할 때 사용합니다. JDBC 로거는 아래와 같은 설정을 입력받습니다:
* [필수] JDBC 프로파일: JDBC 접속 프로파일의 이름을 입력합니다. (JDBC 연동 설정 바로가기)
* [필수] SQL: 데이터 수집에 사용할 SQL 문장을 입력합니다. $where 매크로를 사용할 수 있습니다.
* [필수] 조건절: $where 매크로에 삽입될 조건절을 입력합니다. 물음표(?)를 위치 지정자 (place holder)로 사용할 수 있습니다. 위치 지정자는 마지막 기준 컬럼 값으로 대치됩니다. 입력할 때 where 문자열까지 포함해야 합니다.
* [필수] 기준 컬럼: 매 조회 시 마지막으로 수집했던 행 이후부터 가져올 수 있도록, 검색 기준이 되는 컬럼 이름을 입력합니다. 가령 시퀀스, IDENTITY, auto_increment로 지정된 컬럼, 혹은 증가하는 타임스탬프 컬럼의 이름을 입력합니다.
* [선택] 날짜 컬럼 이름: 데이터가 수집된 날짜를 가지고 있는 컬럼의 이름을 지정합니다.  지정되지 않을 경우 로거가 수집한 날짜를 저장합니다.
* [선택] 날짜 형식: 날짜 컬럼이 SQL 시간 형식이 아닌 문자열이라면 날짜의 형태를 지정할 수 있습니다(예. yyyyMMdd HH:mm:ss).

SQL은 아래의 사항들을 고려하여 작성합니다:
* 기준 컬럼으로 검색할 때 인덱스를 타는지 확인합니다. 인덱스를 타지 않는다면 수천만건 이상 들어있는 테이블의 경우 지속적으로 테이블 풀스캔 부하가 걸릴 수 있습니다.
* 한 번에 가져오는 갯수를 제한합니다. 가령, 오라클의 경우 rownum을 사용하여 가져올 행 갯수를 제한할 수 있습니다. 이를 고려하지 않으면 초기 적재 시에 너무 많은 데이터를 한 번에 가져오려고 시도하면서 문제가 발생할 수 있습니다. JDBC 로거는 지정된 주기별로 쿼리를 수행하지만, 한 번 수집할 때 더 이상 새로운 값이 없을 때까지 쿼리를 반복 수행하므로 가져오는 행 갯수를 제한하는 것이 좋습니다.
* 필요한 컬럼만 SELECT 절에 명시적으로 지정합니다. JDBC 로거는 조회되는 모든 컬럼 값을 키/값 형태로 수집합니다. 불필요한 컬럼을 제외하면 더 나은 성능을 기대할 수 있습니다.

오라클 테이블 데이터 수집 설정 예시

~~~
worldcup-schema
araqne@bombom demo> logapi.createLogger jdbc local dblog
JDBC Profile (required)? worldcup
SQL (required)? select * from (select * from worldcup_weblogs $where order by id) t where rownum < 10000 
Where clause (required)? where id > ?
Column name (required)? id
transformer (optional, enter to skip)?
logger created: name=local\dblog, factory=local\jdbc, status=stopped (interval=0ms), log count=0, last start=null, last run=null, last log=null
~~~

이와 같이 설정된 상태에서 JDBC 로거는 다음과 같이 동작합니다:
* 1.처음에는 $where 절이 빈 문자열로 치환되어 아래와 같은 쿼리를 수행합니다.
~~~
    select * from (select * from worldcup_weblogs order by id) t where rownum < 10000
~~~

* 2.두번째 쿼리부터는 저장된 마지막 id 컬럼 값을 기준으로 다음과 같은 쿼리를 수행합니다.
~~~
    select * from (select * from worldcup_weblogs where id > 9999 order by id) t where rownum < 10000
~~~

* 3.더 이상 데이터가 조회되지 않으면, 다음 실행 주기가 올 때까지 대기합니다.

아래는 JDBC를 통해 수집된 로그가 저장된 테이블을 쿼리한 결과입니다.

~~~
araqne@logdb> query table limit=3 worldcup
{ID=13737450, LINE=10.0.1.130 - - [14/May/1998:14:30:00 +0000] "GET /english/history/past_cups/images/posters/mexico70.gif HTTP/1.0" 200 3211, _id=13737450, _table=worldcup, _time=Thu Aug 15 17:58:19 KST 2013}
{ID=13737449, LINE=10.3.188.218 - - [14/May/1998:14:30:00 +0000] "GET /images/102325s.gif HTTP/1.1" 200 776, _id=13737449, _table=worldcup, _time=Thu Aug 15 17:58:19 KST 2013}
{ID=13737448, LINE=10.0.4.254 - - [14/May/1998:14:30:00 +0000] "GET /images/home_bg_stars.gif HTTP/1.0" 304 -, _id=13737448, _table=worldcup, _time=Thu Aug 15 17:58:19 KST 2013}
total 3 rows, elapsed 0.1s
~~~

## 4.13. FTP 디렉터리 로그 파일 수집 설정

FTP 디렉토리 와치 (ftp-dirwatch) 로거는 FTP를 통해 원격지에서 롤링되지 않는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 가령 일자별 혹은 시간대별로 순차 생성되는 로그 파일을 수집할 때 사용합니다. FTP 디렉토리 와치 로거는 아래와 같은 설정을 입력받습니다:
* [필수] FTP 프로파일: FTP 접속 설정 프로파일의 이름을 입력합니다. (FTP 연동 설정 바로가기)
* [필수] 디렉터리 경로: 로그 파일이 위치하는 파일시스템 경로를 입력합니다.
* [필수] 파일이름 정규표현식 패턴: 디렉터리 경로에 존재하는 파일 중 이름이 정규표현식 패턴에 일치하는 경우에만 수집합니다. 정규표현식 그룹을 쓰는 경우 파일 이름에서 날짜 문자열을 추출합니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다. 파일이름 정규표현식의 그룹으로 추출된 날짜문자열은 가장 앞 부분에 위치합니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 문자집합: 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.

여러 개의 파일이 수집 대상인 경우, 파일의 절대 경로를 사전순으로 정렬하여 순서대로 읽어들입니다. 이하에서는 여러가지 사용 예를 살펴보도록 하겠습니다.

예시 1) /var/log/examples 디렉터리에 example.log.yyyy-MM-dd-HH 로그 파일이 순차 생성되는 경우

0;20130615 141618;192.168.0.10;E002;20130615 141618;192.168.0.11;
* 디렉터리 경로: /var/log/examples
* 파일이름 정규표현식 패턴: example\.log.*
* 날짜 추출 정규표현식 패턴: ^\d+;(\d{8} \d{6});
* 날짜 파싱 포맷: yyyyMMdd HHmmss

예시 2) /logdata/c6509 디렉터리에 c6509.log.yyyyMMdd 로그 파일이 쌓이는 경우

May 01 23:59:59: %LINK-SP-3-UPDOWN: Interface GigabitEthernet8/15, changed state to down
* 디렉터리 경로: /logdata/c6509
* 파일이름 정규표현식 패턴: c6509\.log\.(\d{8})
* 날짜 추출 정규표현식 패턴: ^[^ ]* \d{2} (\d{2}):(\d{2}):(\d{2})
* 날짜 파싱 포맷: yyyyMMddHHmmss(파일이름 정규표현식으로 추출된 yyyyMMdd 그룹 1개와 날짜 추출 정규표현식에서 추출된 HH, mm, ss 그룹 3개가 하나로 병합되어 파싱됩니다.)



## 4.14. FTP 로테이션 로그 파일 수집 설정

FTP 로테이션 (ftp-rotation) 로거는 FTP 서버를 통해서 주기적으로 로테이션 되는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 흔히 리눅스 서버에서는 logrotate 프로그램을 사용하여 일정 주기로 기존 파일의 이름을 변경하여 백업 보관하고 로그 파일을 새로 생성합니다. FTP 로테이션 로거는 이런 시나리오에서 사용되며, 다음과 같은 설정을 입력받습니다:
* [필수] FTP 프로파일: FTP 접속 설정 프로파일의 이름을 입력합니다. (FTP 연동 설정 바로가기)
* [필수] 파일 경로: 주기적으로 로테이션 되는 텍스트 로그 파일의 절대 경로를 입력합니다.
* [선택] 문자집합: 텍스트 파일 해석에 사용할 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 날짜 로케일: 날짜 문자열의 로케일. 가령 날짜 파싱 포맷의 지시자 중 MMM의 해석은 로케일에 따라 “Jan” 혹은 “1월”로 해석됩니다.  기본값은 en입니다.
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.

예시 1) /var/log/httpd/access_log 파일이 로테이션 되는 경우

~~~
127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] "GET /apache_pb.gif HTTP/1.0" 200 2326
~~~

* 파일 경로: /var/log/httpd/access_log
* 날짜 추출 정규표현식 패턴: \[(.*?)\]
* 날짜 파싱 포맷: dd/MMM/yyyy:HH:mm:ss Z
* 날짜 로케일: en

예시 2) /araqne/log/araqne.log 파일이 로테이션 되는 경우

~~~
[2013-06-14 13:55:02,186]  INFO (LogIndexerEngine) - logpresso index: counter reset thread started
[2013-06-14 13:55:40,647]  WARN (ScriptRunner) - script runner: 
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.araqne.console.ScriptRunner.invokeScript(ScriptRunner.java:209)
	at org.araqne.console.ScriptRunner.run(ScriptRunner.java:190)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.InterruptedException
	at org.araqne.console.ReadLineHandler.read(ReadLineHandler.java:156)
	at org.araqne.console.ReadLineHandler.getLine(ReadLineHandler.java:46)
	at org.araqne.console.ConsoleInputStream.readLine(ConsoleInputStream.java:56)
	at org.araqne.script.ScriptContextImpl.readLine(ScriptContextImpl.java:194)
	at org.araqne.log.api.impl.LogApiScript.setOption(LogApiScript.java:629)
	at org.araqne.log.api.impl.LogApiScript.createParser(LogApiScript.java:99)
	... 7 more
~~~

* 파일 경로: /araqne/log/araqne.log
* 날짜 추출 정규표현식 패턴: \[(.*),
* 날짜 파싱 포맷: yyyy-MM-dd HH:mm:ss
* 로그 시작 정규식: \[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\]


## 4.15. SFTP 디렉터리 로그 파일 수집 설정

SFTP 디렉토리 와치 (sftp-dirwatch) 로거는 SFTP를 통해 원격지에서 롤링되지 않는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 가령 일자별 혹은 시간대별로 순차 생성되는 로그 파일을 수집할 때 사용합니다. SFTP 디렉토리 와치 로거는 아래와 같은 설정을 입력받습니다:
* [필수] SSH 프로파일: SSH 접속 설정 프로파일의 이름을 입력합니다. (SSH 연동 설정 바로가기)
* [필수] 디렉터리 경로: 로그 파일이 위치하는 파일시스템 경로를 입력합니다.
* [필수] 파일이름 정규표현식 패턴: 디렉터리 경로에 존재하는 파일 중 이름이 정규표현식 패턴에 일치하는 경우에만 수집합니다. 정규표현식 그룹을 쓰는 경우 파일 이름에서 날짜 문자열을 추출합니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다. 파일이름 정규표현식의 그룹으로 추출된 날짜문자열은 가장 앞 부분에 위치합니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 문자집합: 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.

여러 개의 파일이 수집 대상인 경우, 파일의 절대 경로를 사전순으로 정렬하여 순서대로 읽어들입니다. 이하에서는 여러가지 사용 예를 살펴보도록 하겠습니다.

예시 1) /var/log/examples 디렉터리에 example.log.yyyy-MM-dd-HH 로그 파일이 순차 생성되는 경우

0;20130615 141618;192.168.0.10;E002;20130615 141618;192.168.0.11;
* 디렉터리 경로: /var/log/examples
* 파일이름 정규표현식 패턴: example\.log.*
* 날짜 추출 정규표현식 패턴: ^\d+;(\d{8} \d{6});
* 날짜 파싱 포맷: yyyyMMdd HHmmss

예시 2) /logdata/c6509 디렉터리에 c6509.log.yyyyMMdd 로그 파일이 쌓이는 경우

May 01 23:59:59: %LINK-SP-3-UPDOWN: Interface GigabitEthernet8/15, changed state to down
* 디렉터리 경로: /logdata/c6509
* 파일이름 정규표현식 패턴: c6509\.log\.(\d{8})
* 날짜 추출 정규표현식 패턴: ^[^ ]* \d{2} (\d{2}):(\d{2}):(\d{2})
* 날짜 파싱 포맷: yyyyMMddHHmmss
 (파일이름 정규표현식으로 추출된 yyyyMMdd 그룹 1개와 날짜 추출 정규표현식에서 추출된 HH, mm, ss 그룹 3개가 하나로 병합되어 파싱됩니다.)


## 4.16. SFTP 로테이션 로그 파일 수집 설정

SFTP 로테이션 (sftp-rotation) 로거는 SFTP 서버를 통해서 주기적으로 로테이션 되는 텍스트 로그 파일을 일정 주기마다 수집하려고 할 때 사용합니다. 흔히 리눅스 서버에서는 logrotate 프로그램을 사용하여 일정 주기로 기존 파일의 이름을 변경하여 백업 보관하고 로그 파일을 새로 생성합니다. SFTP 로테이션 로거는 이런 시나리오에서 사용되며, 다음과 같은 설정을 입력받습니다:
* [필수] SSH 프로파일: SSH 접속 설정 프로파일의 이름을 입력합니다. (SSH 연동 설정 바로가기)
* [필수] 파일 경로: 주기적으로 로테이션 되는 텍스트 로그 파일의 절대 경로를 입력합니다.
* [선택] 문자집합: 텍스트 파일 해석에 사용할 문자집합 코드를 입력합니다. 기본값은 utf-8입니다.
* [선택] 날짜 추출 정규표현식 패턴: 로그에서 날짜 문자열을 추출합니다. 정규표현식 그룹으로 묶인 모든 부분을 이어붙여서 하나의 날짜 문자열을 만들어냅니다.
* [선택] 날짜 파싱 포맷: 날짜 문자열을 파싱하는데 사용할 날짜 포맷을 설정합니다. (예: yyyy-MM-dd HH:mm:ss)
* [선택] 날짜 로케일: 날짜 문자열의 로케일. 가령 날짜 파싱 포맷의 지시자 중 MMM의 해석은 로케일에 따라 “Jan” 혹은 “1월”로 해석됩니다.  기본값은 en입니다.
* [선택] 로그 시작 정규식:  로그의 시작 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.
* [선택] 로그 끝 정규식:  로그의 끝 부분을 인식하는 정규표현식을 지정합니다. 멀티라인 로그의 경우에 사용되며, 지정하지 않으면 줄 단위로 읽어들입니다.

예시 1) /var/log/httpd/access_log 파일이 로테이션 되는 경우

~~~
127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] "GET /apache_pb.gif HTTP/1.0" 200 2326
~~~

* 파일 경로: /var/log/httpd/access_log
* 날짜 추출 정규표현식 패턴: \[(.*?)\]
* 날짜 파싱 포맷: dd/MMM/yyyy:HH:mm:ss Z
* 날짜 로케일: en

예시 2) /araqne/log/araqne.log 파일이 로테이션 되는 경우

~~~
[2013-06-14 13:55:02,186]  INFO (LogIndexerEngine) - logpresso index: counter reset thread started
[2013-06-14 13:55:40,647]  WARN (ScriptRunner) - script runner: 
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.araqne.console.ScriptRunner.invokeScript(ScriptRunner.java:209)
	at org.araqne.console.ScriptRunner.run(ScriptRunner.java:190)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.InterruptedException
	at org.araqne.console.ReadLineHandler.read(ReadLineHandler.java:156)
	at org.araqne.console.ReadLineHandler.getLine(ReadLineHandler.java:46)
	at org.araqne.console.ConsoleInputStream.readLine(ConsoleInputStream.java:56)
	at org.araqne.script.ScriptContextImpl.readLine(ScriptContextImpl.java:194)
	at org.araqne.log.api.impl.LogApiScript.setOption(LogApiScript.java:629)
	at org.araqne.log.api.impl.LogApiScript.createParser(LogApiScript.java:99)
	... 7 more
~~~

* 파일 경로: /araqne/log/araqne.log
* 날짜 추출 정규표현식 패턴: \[(.*),
* 날짜 파싱 포맷: yyyy-MM-dd HH:mm:ss
* 로그 시작 정규식: \[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}\]


## 4.17. SSH 표준 출력 수집 설정

SSH 표준 출력 수집 (ssh-exec) 로거는 SSH를 통해 원격으로 지정된 명령어의 실행 결과를 수집합니다. 원격지에 설치된 프로그램 혹은 스크립트 등을 실행하여 표준 출력으로 나오는 문자열 전체를 하나의 로그로 수집합니다. SSH 표준 출력 수집 로거는 아래와 같은 설정을 입력받습니다:
* [필수] SSH 프로파일: SSH 접속 설정 프로파일의 이름을 입력합니다. (SSH 연동 설정 바로가기)
* [필수] 명령어: SSH 쉘 접속 후 실행할 명령어를 입력합니다.

로그 수집 시 매번 접속을 다시 수행하므로, 의도된 간격보다 접속 지연 시간에 따라 수집 간격이 길어질 수 있습니다.

예시) 리눅스 호스트의 load average 로그 수집
* SSH 프로파일 이름: 수집 대상 호스트에 대한 SSH 접속 프로파일 이름을 입력합니다.
* 명령어: cat /proc/loadavg

실시간 로그 트레이스 결과

~~~
araqne> logapi.trace local\loadavg
tracing logger: name=local\loadavg, factory=local\ssh-exec, status=running (interval=1000ms), log count=0, last start=2013-08-18 20:07:39, last run=null, last log=null
local\loadavg: date=2013-08-18 20:07:56, logger=local\loadavg, data={line=0.38 0.17 0.11 1/358 18042}
local\loadavg: date=2013-08-18 20:08:14, logger=local\loadavg, data={line=0.27 0.16 0.11 1/357 18101}
local\loadavg: date=2013-08-18 20:08:32, logger=local\loadavg, data={line=0.21 0.
~~~


## 4.18. JMX 수집 설정

araqne-core 2.6.3, araqne-logdb-jmx 0.1.0 버전부터 지원

원격 JMX 로거는 자바 RMI (Remote Method Invocation) 프로토콜을 사용하여 원격 JVM의 상태 정보를 수집합니다. 모니터링 대상 JVM을 기동할 때 미리 아래와 같은 설정으로 RMI를 활성화시키고, 방화벽에서 RMI 포트를 허용해야 합니다.

### 4.18.1. 모니터링 대상의 원격 JMX 허용과 관련된 JVM 실행 옵션 예시
* -Dcom.sun.management.jmxremote
* -Dcom.sun.management.jmxremote.port=8999
* -Dcom.sun.management.jmxremote.ssl=false
* -Dcom.sun.management.jmxremote.password.file=jmxremote.password
* -Dcom.sun.management.jmxremote.access.file=jmxremote.access

jmxremote.password 파일과 jmxremote.access 파일은 $JAVA_HOME/lib/management/jmxremote.password.template 파일과 $JAVA_HOME/lib/management/jmxremote.access.template 파일을 각각 복사하여 수정 후 사용하시면 됩니다. jmxremote.password 파일 최하단에는 아래와 같은 내용이 있습니다.

~~~
      # monitorRole QED
      # controlRole R&D
~~~

monitorRole의 주석을 해제하고 QED를 적절한 강도의 암호로 변경합니다. 또한, jmxremote.password 파일과 jmxremote.access 파일의 읽기 권한을 제한적으로 설정해야 JVM이 정상적으로 부팅됩니다. 읽기 권한 설정은 아래와 같이 합니다.
* 유닉스 계열
~~~
     chmod 600 jmxremote.password
     chmod 600 jmxremote.access
~~~

* 윈도우즈
~~~
     cacls jmxremote.password /P 계정이름:R
     cacls jmxremote.access /P 계정이름:R
~~~

### 4.18.2. 원격 JMX 로거 설정
* [필수] 호스트 주소: 모니터링 대상의 도메인 이름 혹은 IP 주소를 입력합니다.
* [필수] 포트: 모니터링 대상의 JMX 포트 번호를 입력합니다. 위의 예시에서는 8999에 해당됩니다.
* [필수] 사용자 계정: 모니터링 대상의 JMX 계정을 입력합니다. 위의 예시에서는 monitorRole에 해당됩니다.
* [필수] 암호: 모니터링 대상의 JMX 암호를 입력합니다.
* [필수] 개체 이름: JMX 개체 이름(Object Name)을 입력합니다. 예를 들어, 적재된 클래스 갯수를 보려면 java.lang:type=Classloading을 입력합니다.
* [선택] 속성 이름 목록: 로그로 수집할 속성 이름을 쉼표로 구분하여 명시적으로 지정할 수 있습니다. 지정하지 않으면 전체 속성 정보가 수집됩니다.

### 4.18.3. 원격 JMX 조회 테스트

쉘에서 jmx 명령어를 사용하여 간단하게 사용 가능한 개체 이름의 목록과 속성 정보를 확인할 수 있습니다.

1) 개체 이름 목록 조회 예시

~~~
    araqne@bombom demo> jmx.objectNames localhost:8999 monitorRole QED
     Connecting to host…
    java.lang:type=Memory
     java.lang:type=MemoryPool,name=PS Eden Space
     java.lang:type=MemoryPool,name=PS Survivor Space
     java.lang:type=GarbageCollector,name=PS MarkSweep
     java.lang:type=MemoryPool,name=Code Cache
     java.lang:type=Runtime
     java.lang:type=ClassLoading
     java.nio:type=BufferPool,name=direct
     java.lang:type=Threading
     java.nio:type=BufferPool,name=mapped
     java.util.logging:type=Logging
     java.lang:type=Compilation
     com.sun.management:type=HotSpotDiagnostic
     java.lang:type=MemoryPool,name=PS Perm Gen
     java.lang:type=GarbageCollector,name=PS Scavenge
     java.lang:type=OperatingSystem
     java.lang:type=MemoryPool,name=PS Old Gen
     java.lang:type=MemoryManager,name=CodeCacheManager
     JMImplementation:type=MBeanServerDelegate
~~~

2) 스레딩 속성 정보 조회 예시

~~~
    araqne@bombom demo> jmx.attrs localhost:8999 monitorRole QED java.lang:type=Threading
     Connecting to host…
    ThreadAllocatedMemoryEnabled = true
     ThreadAllocatedMemorySupported = true
     ThreadContentionMonitoringEnabled = false
     CurrentThreadCpuTimeSupported = true
     ObjectMonitorUsageSupported = true
     ThreadContentionMonitoringSupported = true
     AllThreadIds = [J@1f49f731
     CurrentThreadCpuTime = 78000500
     CurrentThreadUserTime = 78000500
     ThreadCount = 72
     TotalStartedThreadCount = 147
     ThreadCpuTimeSupported = true
     ThreadCpuTimeEnabled = true
     DaemonThreadCount = 17
     PeakThreadCount = 83
     SynchronizerUsageSupported = true
     ObjectName = java.lang:type=Threading
~~~


